"""
ุฎุฏูุฉ ุงูุชูููู ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู - DeepSeek API
"""
import os
import json
from typing import Optional
from dotenv import load_dotenv

load_dotenv()

# ููุชุงุญ DeepSeek API
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_BASE_URL = "https://api.deepseek.com"


class AIEvaluationService:
    """ุฎุฏูุฉ ุชูููู ุงููุดุงุฑูุน ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู - DeepSeek"""

    def __init__(self):
        self.api_key = DEEPSEEK_API_KEY
        self.base_url = DEEPSEEK_BASE_URL
        self.max_score = 50  # ุงูุญุฏ ุงูุฃูุตู ููููุงุท
    
    def create_evaluation_prompt(
        self,
        title: str,
        problem_statement: str,
        technical_description: str,
        scientific_reference: str,
        field: str
    ) -> str:
        """ุฅูุดุงุก ูุต ุงูุทูุจ ููุชูููู"""
        prompt = f"""
ุฃูุช ุฎุจูุฑ ูู ุชูููู ุงููุดุงุฑูุน ุงูุชูููุฉ ูุงูุงุจุชูุงุฑูุฉ. ูู ุจุชูููู ุงููุดุฑูุน ุงูุชุงูู:

๐ **ุนููุงู ุงููุดุฑูุน:** {title}

๐ฏ **ุงููุฌุงู:** {field}

โ **ุงููุดููุฉ ุงูุชู ูุญููุง ุงููุดุฑูุน:**
{problem_statement}

๐ป **ุงููุตู ุงูุชููู ุงูุชูุตููู:**
{technical_description}

๐ **ุงููุฑุฌุน ุงูุนููู:**
{scientific_reference}

---

ูู ุจุชูููู ุงููุดุฑูุน ููู ุงููุนุงููุฑ ุงูุชุงููุฉ (ูุฌููุน 25 ููุทุฉ):

1. **ุงูุงุจุชูุงุฑ ูุงูุฅุจุฏุงุน** (0-5 ููุงุท): ูู ุงูููุฑุฉ ูุจุชูุฑุฉ ูุฌุฏูุฏุฉุ
2. **ุงูุฌุฏูู ุงูุชูููุฉ** (0-5 ููุทุฉ): ูู ุงููุดุฑูุน ูุงุจู ููุชูููุฐ ุชูููุงูุ
3. **ุญู ุงููุดููุฉ** (0-5 ููุงุท): ูู ูุญู ุงููุดุฑูุน ูุดููุฉ ุญููููุฉ ุจุดูู ูุนุงูุ
4. **ุงููุตู ุงูุชููู** (0-5 ููุงุท): ูู ุงููุตู ุงูุชููู ุฏููู ูููุตูุ
5. **ุงููุฑุฌุน ุงูุนููู** (0-5 ููุงุท): ูู ุงููุฑุฌุน ุงูุนููู ููุงุณุจ ูุฏุงุนู ููููุฑุฉุ

ุฃุฌุจ ุจุตูุบุฉ JSON ููุท ูุงูุชุงูู:
{{
    "total_score": <ูุฌููุน ุงูููุงุท ูู 25>,
    "detailed_scores": {{
        "innovation": <ููุงุท ุงูุงุจุชูุงุฑ>,
        "feasibility": <ููุงุท ุงูุฌุฏูู>,
        "problem_solving": <ููุงุท ุญู ุงููุดููุฉ>,
        "technical_description": <ููุงุท ุงููุตู ุงูุชููู>,
        "scientific_reference": <ููุงุท ุงููุฑุฌุน ุงูุนููู>
    }},
    "notes": "<ููุงุญุธุงุช ูุชูุตูุงุช ูููุฑูู ุจุงููุบุฉ ุงูุนุฑุจูุฉ>"
}}
"""
        return prompt
    
    async def evaluate_project(
        self,
        title: str,
        problem_statement: str,
        technical_description: str,
        scientific_reference: str,
        field: str
    ) -> dict:
        """ุชูููู ุงููุดุฑูุน ุจุงุณุชุฎุฏุงู AI"""
        
        # ุฅุฐุง ูู ููู ููุงู ููุชุงุญ APIุ ูุณุชุฎุฏู ุชูููู ุชุฌุฑูุจู
        if not self.api_key:
            return self._mock_evaluation(title, technical_description)

        try:
            import openai

            # ุงุณุชุฎุฏุงู DeepSeek API (ูุชูุงูู ูุน OpenAI)
            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )

            prompt = self.create_evaluation_prompt(
                title=title,
                problem_statement=problem_statement,
                technical_description=technical_description,
                scientific_reference=scientific_reference,
                field=field
            )

            response = client.chat.completions.create(
                model="deepseek-chat",  # ูููุฐุฌ DeepSeek
                messages=[
                    {
                        "role": "system",
                        "content": "ุฃูุช ุฎุจูุฑ ูู ุชูููู ุงููุดุงุฑูุน ุงูุชูููุฉ. ุฃุฌุจ ุฏุงุฆูุงู ุจุตูุบุฉ JSON ููุท."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            result_text = response.choices[0].message.content
            
            # ูุญุงููุฉ ุงุณุชุฎุฑุงุฌ JSON
            try:
                # ุฅุฒุงูุฉ ุฃู ูุต ูุจู ุฃู ุจุนุฏ JSON
                start_idx = result_text.find('{')
                end_idx = result_text.rfind('}') + 1
                json_str = result_text[start_idx:end_idx]
                result = json.loads(json_str)
                
                return {
                    "success": True,
                    "score": min(result.get("total_score", 25), self.max_score),
                    "detailed_scores": result.get("detailed_scores", {}),
                    "notes": result.get("notes", "")
                }
            except json.JSONDecodeError:
                return self._mock_evaluation(title, technical_description)
                
        except Exception as e:
            print(f"ุฎุทุฃ ูู ุชูููู AI: {str(e)}")
            return self._mock_evaluation(title, technical_description)
    
    def _mock_evaluation(self, title: str, description: str) -> dict:
        """ุชูููู ุชุฌุฑูุจู ูู ุญุงูุฉ ุนุฏู ุชููุฑ API"""
        import hashlib
        
        # ุฅูุดุงุก ููุงุท ุดุจู ุนุดูุงุฆูุฉ ุจูุงุกู ุนูู ุงููุญุชูู
        hash_input = f"{title}{description}".encode()
        hash_value = int(hashlib.md5(hash_input).hexdigest(), 16)
        
        base_score = 25 + (hash_value % 20)  # 25-44
        
        # ุชูุฒูุน ุงูููุงุท
        innovation = min(10, 5 + (hash_value % 6))
        feasibility = min(15, 8 + (hash_value % 8))
        problem_solving = min(10, 5 + (hash_value % 6))
        tech_desc = min(10, 5 + (len(description) // 500))
        reference = min(5, 2 + (hash_value % 4))
        
        total = innovation + feasibility + problem_solving + tech_desc + reference
        
        notes = """
ุชูููู ุฃููู ูููุดุฑูุน:
- ุงูููุฑุฉ ุชุจุฏู ูุงุนุฏุฉ ููุงุจูุฉ ููุชุทููุฑ
- ูููุตุญ ุจุฅุถุงูุฉ ุงููุฒูุฏ ูู ุงูุชูุงุตูู ุงูุชูููุฉ
- ูููุถู ุชูุถูุญ ุฎุทุฉ ุงูุชูููุฐ ุจุดูู ุฃูุจุฑ
- ุงููุฑุฌุน ุงูุนููู ูุญุชุงุฌ ููุตุงุฏุฑ ุฅุถุงููุฉ
        """.strip()
        
        return {
            "success": True,
            "score": min(total, self.max_score),
            "detailed_scores": {
                "innovation": innovation,
                "feasibility": feasibility,
                "problem_solving": problem_solving,
                "technical_description": tech_desc,
                "scientific_reference": reference
            },
            "notes": notes
        }
    
    def calculate_final_score(
        self,
        admin_evaluations: list,  # [{"score": x, "weight": y}, ...]
        ai_score: float
    ) -> dict:
        """ุญุณุงุจ ุงููุชูุฌุฉ ุงูููุงุฆูุฉ"""
        # 75% ููุฅุฏุงุฑููู (ููุฒุนุฉ ุญุณุจ ุงูุฃูุฒุงู)
        # 25% ูู AI
        
        if admin_evaluations:
            total_weight = sum(e.get("weight", 10) for e in admin_evaluations)
            weighted_admin_score = sum(
                e.get("score", 0) * e.get("weight", 10) 
                for e in admin_evaluations
            ) / total_weight if total_weight > 0 else 0
        else:
            weighted_admin_score = 0
        
        # ุงูุฏุฑุฌุฉ ุงูููุงุฆูุฉ ูู 100
        final_score = (weighted_admin_score * 0.5) + (ai_score * 0.5)
        
        return {
            "admin_score": round(weighted_admin_score, 2),
            "ai_score": round(ai_score, 2),
            "final_score": round(final_score, 2),
            "max_possible": 50
        }


# ุฅูุดุงุก ูุณุฎุฉ ูู ุงูุฎุฏูุฉ
ai_evaluation_service = AIEvaluationService()
